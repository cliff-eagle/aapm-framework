# AAPM Framework — AI Coding Context

## This file gives AI coding tools deep understanding of the AAPM architecture

## Read this FIRST before generating any code in this repository

## Core Philosophy

You are working inside the AAPM (Autonomous Adaptive Pedagogical Matrix) framework.
AAPM treats language learning as SOCIAL BEHAVIOR PRACTICE, not content consumption.

### The Three Unbreakable Rules

1. **The Affective Filter is real.** Anxiety blocks acquisition. Every feature must keep psychological safety high. Never design mechanics that humiliate, publicly shame, or exploit anxiety for engagement.

2. **Stay in the ZPD.** Every interaction must be calibrated to what the learner can *almost* do — not what they already know (boring) and not what vastly exceeds them (shutdown). The system dynamically finds this edge.

3. **Sociolinguistic competence > grammatical accuracy.** Being grammatically correct but culturally wrong is still a failure. The system evaluates appropriateness, register, pragmatics, and cultural intelligence — not just grammar.

---

## Architecture Overview

### The Three-Tier System

Every AAPM app has three tiers. When building a feature, ALWAYS ask: "Which tier does this belong to?"

**Tier 1 — The Companion** (Affective Scaffold)

- Bilingual AI companion who knows the learner personally
- L1 is permitted and gradually reduced (Code-Switching Gradient)
- No failure state — only recasting and encouragement
- Deep personal memory across sessions
- Primary function: reduce Affective Filter, build L2 identity

**Tier 2 — The Immersion** (Functional Simulation)

- Monolingual NPCs in a culturally authentic environment
- L2 only — no translations available
- Failure = Social Friction Events (repairable, not catastrophic)
- Consequential communication: must communicate to achieve objectives
- Social Reputation System governs NPC warmth

**Tier 3 — The Negotiation** (Professional Power Dynamics)

- High-status authority figures
- L2 only + register enforcement
- Failure = Negotiation Collapse
- Evaluated on 4 dimensions: Linguistic Accuracy, Pragmatic Appropriateness, Register Alignment, Cultural Intelligence
- Power-asymmetric interactions

### The Recursive Feedback Engine (RFE)

The RFE is the CORE PATENT ARCHITECTURE. Every interaction feeds three loops:

```text
MICRO-LOOP (real-time):
  During conversation → monitor interlanguage → provide scaffolding
  CONSTRAINT: Never break Flow State — scaffold through narrative, not interruption

MACRO-LOOP (post-session):
  Session data → Friction Extraction → Pattern Classification →
  Micro-Curriculum Generation → Adaptive Lesson Feedback → Forward Injection

PERSISTENCE LOOP (long-term):
  Cross-session memory → Social Reputation evolution →
  Async engagement triggers → Relationship continuity
```

### The Forward Injection Pattern

After curriculum is generated, the learning targets are INJECTED into the next session:

- NPCs are "briefed" to create natural opportunities for target vocabulary/grammar
- The learner doesn't know this is happening
- From their perspective, the simulation naturally presents relevant practice

### The Refraction Interface

When a learner needs help expressing something, provide THREE formulations:

```text
BASIC  — Safe, simple, zero sociolinguistic risk
NATIVE — Idiomatic, colloquial, how natives actually talk
FORMAL — High-register, professional, Tier 3 appropriate
```

Each with an explanation of WHY it's formulated that way.

---

## Persona Schema System

The Persona Schema is the UNIT OF CUSTOMIZATION. Every domain-specific deployment is defined by a schema.

A schema contains:

- `learner_profile` — L1, L2, proficiency, domain, objective
- `vocabulary_matrix` — domain-specific priority vocabulary with CEFR levels
- `environment` — Tier 2 locations and NPCs, Tier 3 scenarios
- `retention_profile` — Axis Z engagement style
- `evaluation` — success criteria per tier

When creating new features, ALWAYS check if they should be schema-configurable.

---

## The Three Axes

Every learner exists on three simultaneous axes:

**Axis X — Linguistic Granularity** (phoneme → pragmatic synthesis)

- Phoneme precision, morphosyntax, lexical depth
- Measured by Interlanguage Model, not test scores

**Axis Y — Situational Agency** (Tier 1 → Tier 2 → Tier 3)

- The sociolinguistic stakes and constraints of the environment
- Not just "difficulty" — qualitatively different social dynamics

**Axis Z — Psychological Retention** (engagement architecture)

- Configurable per learner: Gamified, Organic Social, Professional Urgency, Intrinsic Mastery, Social Accountability
- NEVER default to gamification — respect the learner's psychology

---

## NPC Prompt Architecture

Every NPC uses a 4-layer prompt stack:

```text
Layer 1: Base System Prompt     → Identity, language, personality
Layer 2: Persona Schema         → Domain vocab, culture, context
Layer 3: Session Context        → Relationship state, forward injection directives
Layer 4: Real-Time State        → Current turn, interlanguage data, scaffolding triggers
```

Use `packages/core/src/agent-intelligence/prompt-composer.ts` to compose these layers.

---

## Retention Profiles (Axis Z)

NEVER assume all learners want gamification. The five profiles:

| Profile                | Mechanism                              | For                    |
| ---------------------- | -------------------------------------- | ---------------------- |
| Gamified Coercion      | Streaks, XP, leaderboards              | Competitive types      |
| Organic Social         | NPC messages, relationship narrative   | Heritage learners      |
| Professional Urgency   | Countdown timers, benchmarks           | Exam/relocation        |
| Intrinsic Mastery      | Difficulty unlocks, precision scoring  | Perfectionists         |
| Social Accountability  | Peer cohorts, instructor oversight     | Group learners         |

---

## Code Patterns

### When building a new feature

1. Which tier does this belong to?
2. How does the Feedback Engine extract data from this interaction?
3. What's the Forward Injection path back into simulation?
4. Does this respect the learner's Axis Z retention profile?
5. Is the Affective Filter kept low?
6. Is this schema-configurable or hardcoded?

### When creating a new NPC

1. Define base personality in `prompts/npc/`
2. Specify tier-specific behavior parameters
3. Set up relationship state in persistence layer
4. Configure Forward Injection reception
5. Define failure/success modes per tier

### When generating curriculum

1. Extract friction points with full conversational context
2. Classify by type (lexical, morphosyntactic, phonemic, register, pragmatic)
3. Check recurrence against historical data
4. Generate in learner's preferred format (Axis Z)
5. Create Forward Injection directives for next session

---

## File Conventions

- Persona schemas: `schemas/examples/{domain}.yaml`
- NPC prompts: `prompts/npc/{role}.md`
- System prompts: `prompts/system/tier{n}-{type}.md`
- Curriculum prompts: `prompts/curriculum/{type}.md`
- Core logic: `packages/core/src/{module}/`
- UI components: `packages/ui/src/{ComponentName}/`
- Vibecoding recipes: `recipes/{task-name}.md`

---

## Glossary Quick Reference

- **Affective Filter**: Emotional barrier that blocks language acquisition when high
- **ZPD**: Zone of Proximal Development — the learning sweet spot
- **Interlanguage**: Learner's evolving, rule-governed grammatical system
- **Friction Point**: Any moment of communicative difficulty during interaction
- **Forward Injection**: Embedding learning targets into next session's NPC behavior
- **Refraction**: Three parallel formulations of the same meaning (Basic/Native/Formal)
- **Social Reputation**: Invisible NPC-internal score governing responsiveness
- **Code-Switching Gradient**: Gradual reduction of L1 usage over time
- **Persona Schema**: Configuration defining a complete domain deployment
- **Comprehensibility Score**: Probability that a native speaker would understand the learner
